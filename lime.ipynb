{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e6a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd5393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20e85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lime import lime_image\n",
    "from skimage.segmentation import slic\n",
    "from ultralytics import YOLO\n",
    "import numpy as np\n",
    "\n",
    "model_path = \"D:/BTXRD-Code/Object-Detection/runs/detect/paper-data/weights/paper-best.pt\"\n",
    "model = YOLO(model_path)\n",
    "model.conf = 0.01 \n",
    "print(model.names)\n",
    "\n",
    "def yolo_predict_fn(images):\n",
    "    \"\"\"\n",
    "    images: list of images (numpy arrays)\n",
    "    return: list of confidence scores for the target box (e.g., dog box)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for img in images:\n",
    "        print(\"Input shape:\", img.shape, \"dtype:\", img.dtype)  # Debug info\n",
    "        preds = model(img)  # dùng YOLOv8 predict\n",
    "        probs = np.zeros(len(model.names))\n",
    "        for pred in preds:\n",
    "            for box in pred.boxes:\n",
    "                class_id = int(box.cls[0])\n",
    "                confidence = box.conf[0]\n",
    "                probs[class_id] = max(probs[class_id], confidence)\n",
    "        results.append(probs)\n",
    "\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa3a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2 import model_zoo\n",
    "\n",
    "# ---------- Load Detectron2 Model ----------\n",
    "def load_detectron2_model(config_path=\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\",\n",
    "                          num_classes=2, weights_path=None, score_thresh=0.5):\n",
    "    cfg = get_cfg()\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(config_path))\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = num_classes\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = score_thresh\n",
    "    cfg.MODEL.DEVICE = \"cuda\"\n",
    "\n",
    "    if weights_path:\n",
    "        cfg.MODEL.WEIGHTS = weights_path\n",
    "    else:\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(config_path)\n",
    "\n",
    "    return DefaultPredictor(cfg)\n",
    "\n",
    "predictor = load_detectron2_model(num_classes=2, weights_path=\"./detectron_runs/model_best_6280.pth\", score_thresh=0.1)\n",
    "\n",
    "# ---------- Predictor Function for LIME ----------\n",
    "def detectron2_predict_fn(images):\n",
    "    results = []\n",
    "    for img in images:\n",
    "        preds = predictor(img)\n",
    "        instances = preds[\"instances\"].to(\"cpu\")\n",
    "        scores = np.zeros(2)\n",
    "        for cls_id, conf in zip(instances.pred_classes.numpy(), instances.scores.numpy()):\n",
    "            scores[cls_id] = max(scores[cls_id], conf)\n",
    "        results.append(scores)\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544e2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import nbimporter\n",
    "from ensemble_boxes import weighted_boxes_fusion\n",
    "from ensemblee_wbf import yolo_predict_from_image, detectron2_predict_from_image, load_yolo_model, load_detectron2_model\n",
    "\n",
    "yolo_model = load_yolo_model(\"./runs/detect/paper-data/weights/paper-best.pt\", confidence_threshold=0.01, iou_threshold=0.6)\n",
    "detectron_model = load_detectron2_model(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\", 2, \"./detectron_runs/model_best_6280.pth\", score_thresh=0.01)\n",
    "\n",
    "\n",
    "def ensemblee_detection_predict_fn(images):\n",
    "    \"\"\"\n",
    "    Predict function for LIME with list of RGB numpy arrays (already resized).\n",
    "    Returns: Numpy array of shape (N, num_classes) with confidence scores.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    num_classes = 2  # Set this to the number of classes in your model\n",
    "\n",
    "    for img in images:      \n",
    "        img_h, img_w = img.shape[:2]\n",
    "        # Run predictions\n",
    "        yolo_preds = yolo_predict_from_image(yolo_model, img, 608)\n",
    "        d2_preds = detectron2_predict_from_image(detectron_model, img)\n",
    "\n",
    "        # Prepare boxes for WBF\n",
    "        def prepare(preds):\n",
    "            boxes, scores, labels = [], [], []\n",
    "            for pred in preds:\n",
    "                xmin, ymin, width, height = pred[\"bbox\"]\n",
    "                x1 = xmin / img_w\n",
    "                y1 = ymin / img_h\n",
    "                x2 = (xmin + width) / img_w\n",
    "                y2 = (ymin + height) / img_h\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "                scores.append(pred[\"score\"])\n",
    "                labels.append(pred[\"category_id\"])\n",
    "            return boxes, scores, labels\n",
    "\n",
    "        yolo_boxes, yolo_scores, yolo_labels = prepare(yolo_preds)\n",
    "        d2_boxes, d2_scores, d2_labels = prepare(d2_preds)\n",
    "\n",
    "        all_boxes = [yolo_boxes, d2_boxes]\n",
    "        all_scores = [yolo_scores, d2_scores]\n",
    "        all_labels = [yolo_labels, d2_labels]\n",
    "\n",
    "        # Apply Weighted Box Fusion\n",
    "        boxes_fused, scores_fused, labels_fused = weighted_boxes_fusion(\n",
    "            all_boxes, all_scores, all_labels, iou_thr=0.55, skip_box_thr=0.0001\n",
    "        )\n",
    "\n",
    "        # Build class probabilities\n",
    "        probs = np.zeros(num_classes)\n",
    "        for score, label in zip(scores_fused, labels_fused):\n",
    "            probs[int(label)] = max(probs[int(label)], score)\n",
    "\n",
    "        results.append(probs)\n",
    "\n",
    "    return np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01e1160",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from xai_utils_benmarks import deletion_curve, min_subset, load_yolo_mask, pointing_game, extended_pointing_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f5c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "val_folder = r'D:\\BTXRD-Dataset\\BTXRD-Yolo\\val\\images'\n",
    "groundtruth_folder = r'D:\\BTXRD-Dataset\\BTXRD-Yolo\\val\\labels'\n",
    "output_csv_path = 'yolo_lime_results.csv'\n",
    "output_folder_label_0 = 'LIME_runs\\yolo-predict-lime-label-0'\n",
    "output_folder_label_1 = 'LIME_runs\\yolo-predict-lime-label-1'\n",
    "explainer = lime_image.LimeImageExplainer()\n",
    "\n",
    "results = []\n",
    "#  0: B-tumor\n",
    "#  1: M-tumor\n",
    "for image_name in os.listdir(val_folder):\n",
    "    image_path = os.path.join(val_folder, image_name)\n",
    "\n",
    "    input_image = cv2.imread(image_path)\n",
    "    original_height, original_width = input_image.shape[:2]\n",
    "    target_width = 608\n",
    "    aspect_ratio = original_width / original_height\n",
    "    new_height = int(target_width / aspect_ratio)\n",
    "    input_image_resized = cv2.resize(input_image, (target_width, new_height))\n",
    "       \n",
    "    # Tạo giải thích cho ảnh\n",
    "    explanation = explainer.explain_instance(\n",
    "        input_image_resized,\n",
    "        yolo_predict_fn,\n",
    "        top_labels=2,  \n",
    "        hide_color=0,\n",
    "        num_samples=1000\n",
    "    )\n",
    "\n",
    "    # Hiển thị và lưu lại giải thích cho lớp B-Tumor (label=0)\n",
    "    temp, mask = explanation.get_image_and_mask(\n",
    "        label=0, \n",
    "        positive_only=True,\n",
    "        num_features=10,\n",
    "        hide_rest=False\n",
    "    )\n",
    "\n",
    "    segments = explanation.segments  \n",
    "\n",
    "    # Lặp qua label 0 và 1\n",
    "    for label, output_folder in zip([0, 1], [output_folder_label_0, output_folder_label_1]):\n",
    "        weights = dict(explanation.local_exp[label])\n",
    "        importance_map = np.zeros_like(segments, dtype=float)\n",
    "\n",
    "        # Gán trọng số dương vào bản đồ importance\n",
    "        for sp_id, weight in weights.items():\n",
    "            importance_map[segments == sp_id] = weight if weight > 0 else 0.0\n",
    "\n",
    "        \n",
    "        # Chuẩn hóa từ 0 đến 1\n",
    "        flat = importance_map.flatten().reshape(-1, 1)\n",
    "        normalized_map = MinMaxScaler().fit_transform(flat).reshape(importance_map.shape)\n",
    "        normalized_map_resized = cv2.resize(normalized_map, (original_width, original_height))\n",
    "\n",
    "        print(f\"Image: {image_name}, Label: {label}, Max Importance: {np.max(normalized_map_resized)}, Min Importance: {np.min(normalized_map_resized)}\")\n",
    "        print(normalized_map)\n",
    "\n",
    "        # Vẽ heatmap\n",
    "        fig, ax = plt.subplots(figsize=(6, 6))\n",
    "        ax.imshow(cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB))\n",
    "        heatmap = ax.imshow(normalized_map_resized, cmap='jet', alpha=0.25, vmin=0, vmax=1)\n",
    "        plt.colorbar(heatmap, ax=ax, fraction=0.046, pad=0.04)\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'LIME Heatmap (Label {label}) - {image_name}')\n",
    "\n",
    "        # Lưu hình\n",
    "        heatmap_output_path = os.path.join(output_folder, f\"heatmap_label{label}_{image_name}\")\n",
    "        plt.savefig(heatmap_output_path, bbox_inches='tight', pad_inches=0)\n",
    "        plt.close()\n",
    "\n",
    "        # Load ground truth mask\n",
    "        gt_file = os.path.join(groundtruth_folder, os.path.splitext(image_name)[0] + '.txt')\n",
    "        gt_mask = load_yolo_mask(gt_file, (original_height, original_width), class_filter=label)\n",
    "\n",
    "        # Tính toán XAI metrics\n",
    "        sorted_segments = sorted(weights.items(), key=lambda x: -x[1])\n",
    "        mask_order = [seg_id for seg_id, _ in sorted_segments]\n",
    "      \n",
    "        # Tính chỉ số Deletion và D-Deletion\n",
    "        auc_deletion = deletion_curve(input_image_resized.copy(), segments, mask_order, yolo_predict_fn, label, mode='zero')      \n",
    "\n",
    "        # Tính chỉ số Min-Subset và D-Min-Subset\n",
    "        min_subset_score = min_subset(input_image_resized.copy(), segments, weights, yolo_predict_fn, label, threshold=0.9, mode='zero')\n",
    "       \n",
    "        # Tính chỉ số Pointing Game và Extended Pointing Game\n",
    "        pg_score = pointing_game(normalized_map_resized, gt_mask)\n",
    "        ebpg_score = extended_pointing_game(normalized_map_resized, gt_mask, top_percent=0.01)\n",
    "\n",
    "        # Ghi lại kết quả\n",
    "        results.append({\n",
    "            'image': image_name,\n",
    "            'label': label,\n",
    "            'auc_deletion': auc_deletion,\n",
    "            'auc_d_deletion': 0, # Chưa tính toán\n",
    "            'min_subset': min_subset_score,\n",
    "            'd_min_subset': 0, # Chưa tính toán\n",
    "            'pointing_game': pg_score,\n",
    "            'extended_pointing_game': ebpg_score,\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "print(f\"Saved metrics to {output_csv_path}\")\n",
    "\n",
    "# Tính trung bình từng chỉ số theo từng label\n",
    "mean_metrics_per_label = df.groupby('label')[['auc_deletion', 'auc_d_deletion', 'min_subset', 'd_min_subset', 'pointing_game', 'extended_pointing_game']].mean()\n",
    "\n",
    "# Tạo DataFrame các dòng tổng trung bình cho mỗi label\n",
    "mean_rows = pd.DataFrame({\n",
    "    'image': ['mean'] * len(mean_metrics_per_label),\n",
    "    'label': mean_metrics_per_label.index,\n",
    "    'auc_deletion': mean_metrics_per_label['auc_deletion'].values,\n",
    "    'auc_d_deletion': mean_metrics_per_label['auc_d_deletion'].values,\n",
    "    'min_subset': mean_metrics_per_label['min_subset'].values,\n",
    "    'd_min_subset': mean_metrics_per_label['d_min_subset'].values,\n",
    "    'pointing_game': mean_metrics_per_label['pointing_game'].values,\n",
    "    'extended_pointing_game': mean_metrics_per_label['extended_pointing_game'].values,\n",
    "})\n",
    "\n",
    "print(\"Mean metrics per label:\")\n",
    "print(mean_rows)\n",
    "\n",
    "# Ghi thêm các dòng tổng trung bình theo label vào file CSV (append, không header)\n",
    "mean_rows.to_csv(output_csv_path, mode='a', header=False, index=False)\n",
    "\n",
    "print(\"Saved mean metrics per label as additional rows in the CSV file.\")\n",
    "print(f\"Completed processing.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "detectron2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
